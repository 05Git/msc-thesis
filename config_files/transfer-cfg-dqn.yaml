folders:
  parent_dir: "./transfer_agents/"
  model_name: "test_dqn_agent"

policy_kwargs:
  #net_arch: [{ pi: [64, 64], vf: [32, 32] }]
  #net_arch: [64, 64]
  #dueling: True

dqn_settings:
  policy_type: "MultiInputPolicy"
  gamma: 0.94
  model_checkpoint: "0"
  learning_rate: [2.5e-4, 2.5e-6] # To start
  buffer_size: 100_000
  learning_starts: 100 # how many steps of the model to collect transitions for before learning starts
  batch_size: 64 # Minibatch size for each gradient update
  tau: 1.0
  train_freq: !!python/tuple [4, "steps"]
  autosave_freq: 250_000
  time_steps: 500_000
  n_train_epochs: 4
  n_eval_episodes: 5
  seeds: !!python/tuple [ 0 ]

  replay_buffer_class: PrioritizedReplayBuffer    # Rollout buffer class to use. If None, it will be automatically selected.
  replay_buffer_kwargs: # Keyword arguments to pass to the rollout buffer on creation.
    alpha: 0.6 # Importance-sampling exponent
    beta: 0.4 # Initial value of importance-sampling correction
  target_update_interval: 1000 # Update the target network every target_update_interval environment steps.
  exploration_fraction: 0.5
  exploration_initial_eps: 1.0
  exploration_final_eps: 0.05
  gradient_steps: 1
  max_grad_norm: 10
  stats_window_size: 100 # Window size for the rollout logging, specifying the number of episodes to average the reported success rate, mean episode length, and mean reward over
