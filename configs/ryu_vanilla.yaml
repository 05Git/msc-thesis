folders:
  parent_dir: whiff_penalty_tests
  model_name: 5e-3

misc:
  seed: 500
  num_players: 1
  num_train_envs: 8
  num_eval_envs: 4
  timesteps: 500_000
  model_checkpoint: "0_autosave_150000"
  n_eval_episodes: 100

policy_settings:
  policy: CnnPolicy
  gamma: 0.99
  learning_rate: [2.5e-5, 2.5e-6]
  clip_range: [0.15, 0.025]
  # learning_rate: [5.0e-5, 2.5e-6] # Finetuning
  # clip_range: [0.075, 0.025]      # Finetuning
  n_epochs: 10
  n_steps: 128
  batch_size: 1024 # batch_size % num_envs should equal 0
  gae_lambda: 0.95
  ent_coef: 0.
  vf_coef: 0.5
  target_kl: null
  max_grad_norm: 0.5
  use_sde: False
  sde_sample_freq: -1
  normalize_advantage: True
  stats_window_size: 100
  verbose: 1

callbacks_settings:
  autosave: True
  check_freq: 50_000
  arcade_metrics: True

env_settings:
  shared:
    game_id: sfiii3n
    step_ratio: 6
    frame_shape: !!python/tuple [84, 84, 1]
    continue_game: 0.
    action_space: multi_discrete
    outfits: 1
    splash_screen: False
  train:
    characters: Ryu
    difficulty: 6
    super_art: 1
  eval:
    characters: Ryu
    difficulty: 6
    super_art: 1

wrappers_settings:
  normalize_reward: True
  normalization_factor: 1.0
  no_attack_buttons_combinations: False
  stack_frames: 4
  dilation: 1
  add_last_action: False
  stack_actions: 1
  repeat_action: 1
  scale: False
  exclude_image_scaling: False
  role_relative: False
  filter_keys: [frame]
  flatten: True
  wrappers: [
    [pixelobs, {}],
    # [opp_controller, {
    #   opp_type: rand
    # }],
    # [2ptrain, {}],
    [whiff_penalty, {
      whiff_penalty: -5.e-3
    }],
    # [move_bonus, {
    #   move_bonus: 1.e-4
    # }]
  ]
