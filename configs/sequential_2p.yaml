folders:
  parent_dir: base_policies
  model_name: sequential

misc:
  seed: 800
  num_players: 2
  num_train_envs: 8
  num_eval_envs: 4
  timesteps: 500_000
  model_checkpoint: "1000000" # "500000", "1000000"
  n_eval_episodes: 100

policy_settings:
  policy: CnnPolicy
  gamma: 0.99
  # learning_rate: [2.5e-5, 2.5e-6]
  # clip_range: [0.15, 0.025]
  learning_rate: [5.0e-5, 2.5e-6] # Finetuning
  clip_range: [0.075, 0.025]      # Finetuning
  n_epochs: 10
  n_steps: 128
  batch_size: 1024 # batch_size % num_envs should equal 0
  gae_lambda: 0.95
  ent_coef: 0.
  vf_coef: 0.5
  target_kl: null
  max_grad_norm: 0.5
  use_sde: False
  sde_sample_freq: -1
  normalize_advantage: True
  stats_window_size: 100
  verbose: 1

callbacks_settings:
  autosave: False
  check_freq: 250_000
  arcade_metrics: True

env_settings:
  shared:
    game_id: sfiii3n
    step_ratio: 6
    frame_shape: !!python/tuple [84, 84, 1]
    continue_game: 0.
    action_space: multi_discrete
    outfits: !!python/tuple [1, 1]
    splash_screen: False
  train:
    characters: !!python/tuple [Ryu, null]
    difficulty: 6
    super_art: !!python/tuple [1, 1]
  eval:
    characters: !!python/tuple [Ryu, null]
    difficulty: 6
    super_art: !!python/tuple [1, 1]

wrappers_settings:
  normalize_reward: True
  normalization_factor: 1.0
  no_attack_buttons_combinations: False
  stack_frames: 4
  dilation: 1
  add_last_action: False
  stack_actions: 1
  repeat_action: 1
  scale: False
  exclude_image_scaling: False
  role_relative: False
  filter_keys: [frame, P1_health, P2_health, timer]
  flatten: True
  wrappers: [
    [att_train, {}], # att_train, def_train, att_train
    [pixelobs, {}],
    [opp_controller, {
      opp_type: jump # rand, rand, jump
    }],
    [2ptrain, {}],
  ]
